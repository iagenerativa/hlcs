# HLCS - High-Level Consciousness System

**Version**: 3.0.0 (Autonomous Intelligence) ğŸ§   
**API Protocol**: gRPC + REST (dual)  
**Integration**: SARAi MCP Server + Phi4MiniAGI + Meta-Consciousness + Strategic Planning + Multi-Stakeholder SCI  
**Migration Status**: ğŸŸ¡ [sarai-agi integration pending approval](docs/SARAI_AGI_MIGRATION_STATUS.md)

---

## ğŸ¯ Overview

HLCS v3.0 is the **autonomous orchestration layer** for SARAi AGI with true intelligence. It provides:

- **Meta-Consciousness Layer** (v0.2): Self-awareness and introspection
- **Strategic Planning System** (v0.5): Goal-oriented planning and execution
- **Multi-Stakeholder SCI** (v0.4): Consensus-based decision making
- **API-first design** with gRPC + REST dual protocol
- **Custom orchestrator** (no LangGraph/CrewAI bloat)
- **Multi-modal intelligence** (text, vision, audio)
- **Iterative refinement** with meta-cognitive quality evaluation
- **MCP integration** with SARAi tools
- **AGI System** with Phi-4-mini + RAG + Memory + Agents

**Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HLCS v3.0 (Port 4000/4001)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  gRPC Server (4000)         â† Future                â”‚  â”‚
â”‚  â”‚  REST Gateway (4001)        â† Production âœ…         â”‚  â”‚
â”‚  â”‚    + /api/v1/planning/* ğŸ†•                         â”‚  â”‚
â”‚  â”‚    + /api/v1/sci/* ğŸ†•                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Meta-Consciousness Layer ğŸ†•                       â”‚  â”‚
â”‚  â”‚  â€¢ IgnoranceConsciousness                          â”‚  â”‚
â”‚  â”‚  â€¢ SelfDoubtScore                                  â”‚  â”‚
â”‚  â”‚  â€¢ NarrativeConsciousness                          â”‚  â”‚
â”‚  â”‚  â€¢ Autonomous routing decisions                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Strategic Planning System ğŸ†•                      â”‚  â”‚
â”‚  â”‚  â€¢ GoalManager (hierarchical goals)                â”‚  â”‚
â”‚  â”‚  â€¢ PlanExecutor (plan decomposition)               â”‚  â”‚
â”‚  â”‚  â€¢ ProgressTracker (milestones)                    â”‚  â”‚
â”‚  â”‚  â€¢ ScenarioSimulator (what-if analysis)            â”‚  â”‚
â”‚  â”‚  â€¢ HypothesisTester (validation)                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Multi-Stakeholder SCI ğŸ†•                          â”‚  â”‚
â”‚  â”‚  â€¢ Weighted consensus (60/30/10)                   â”‚  â”‚
â”‚  â”‚  â€¢ VotingStrategy (flexible mechanisms)            â”‚  â”‚
â”‚  â”‚  â€¢ ConsensusBuilder (conflict resolution)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Autonomous Orchestrator v3.0                      â”‚  â”‚
â”‚  â”‚  â€¢ Meta-cognitive analysis                         â”‚  â”‚
â”‚  â”‚  â€¢ Intelligent component routing                   â”‚  â”‚
â”‚  â”‚  â€¢ Workflow: simple/complex/multimodal/agi/ensembleâ”‚  â”‚
â”‚  â”‚  â€¢ Quality evaluation                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ SARAi MCP Client â”‚    â”‚ Phi4MiniAGI System         â”‚ â”‚
â”‚  â”‚ â€¢ saul.respond   â”‚    â”‚ â€¢ Phi-4-mini LLM           â”‚ â”‚
â”‚  â”‚ â€¢ rag.search     â”‚    â”‚ â€¢ KnowledgeRAG             â”‚ â”‚
â”‚  â”‚ â€¢ vision.analyze â”‚    â”‚ â€¢ CodeAgent (ReAct)        â”‚ â”‚
â”‚  â”‚ â€¢ audio.transc.  â”‚    â”‚ â€¢ MemoryBuffer (episodic)  â”‚ â”‚
â”‚  â”‚ â€¢ trm.classify   â”‚    â”‚ â€¢ Auto strategy selection  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

```bash
# Python 3.11+ (3.12+ recommended)
python --version

# Install gRPC tools
pip install grpcio grpcio-tools

# Clone repo
git clone https://github.com/iagenerativa/hlcs.git
cd hlcs
```

### 2. Generate gRPC Code from Proto

```bash
# Generate Python stubs
python -m grpc_tools.protoc \
  -I./proto \
  --python_out=./src/hlcs/grpc_server \
  --grpc_python_out=./src/hlcs/grpc_server \
  ./proto/hlcs.proto ./proto/sarai_mcp.proto
```

### 3. Configure Environment

```bash
cp .env.example .env

# Edit .env
SARAI_MCP_URL=http://localhost:3000
HLCS_GRPC_PORT=4000
HLCS_REST_PORT=4001
COMPLEXITY_THRESHOLD=0.5
QUALITY_THRESHOLD=0.7
MAX_ITERATIONS=3
```

### 4. Run with Docker

```bash
# Build
docker-compose build

# Run HLCS + SARAi
docker-compose up
```

**Or run locally**:
```bash
# Install dependencies
pip install -r requirements.txt

# Run gRPC server
python -m src.hlcs.grpc_server.server

# In another terminal, run REST gateway
python -m src.hlcs.rest_gateway.server
```

---

## ğŸ“¡ API Usage

### gRPC (Production)

```python
import grpc
from hlcs_pb2 import QueryRequest, ProcessingOptions
from hlcs_pb2_grpc import HLCSStub

# Connect
channel = grpc.insecure_channel('localhost:4000')
client = HLCSStub(channel)

# Simple query
request = QueryRequest(
    query="Â¿QuÃ© tiempo hace hoy?",
    options=ProcessingOptions(quality_threshold=0.8)
)

response = client.ProcessQuery(request)
print(f"Result: {response.result}")
print(f"Quality: {response.quality_score}")
print(f"Time: {response.processing_time_ms}ms")
```

### REST (Debug/Web)

```bash
# Simple query
curl -X POST http://localhost:4001/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explica quÃ© es un agujero negro",
    "options": {
      "quality_threshold": 0.8,
      "max_iterations": 3
    }
  }'

# Multimodal query (with image)
curl -X POST http://localhost:4001/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Â¿QuÃ© hay en esta imagen?",
    "image_url": "https://example.com/image.jpg",
    "options": {"strategy": "multimodal"}
  }'

# Status
curl http://localhost:4001/api/v1/status

# Capabilities
curl http://localhost:4001/api/v1/capabilities
```

### Streaming (gRPC)

```python
# Long-running query with streaming
request = QueryRequest(
    query="Analiza este paper de 50 pÃ¡ginas...",
    options=ProcessingOptions(enable_streaming=True)
)

for chunk in client.ProcessQueryStream(request):
    if chunk.type == QueryStreamChunk.STATUS:
        print(f"Status: {chunk.content}")
    elif chunk.type == QueryStreamChunk.PARTIAL_RESULT:
        print(f"Partial: {chunk.content}")
    elif chunk.type == QueryStreamChunk.FINAL_RESULT:
        print(f"Final: {chunk.content}")
        break
```

---

## ğŸ§  Orchestration Logic

### 1. Complexity Classification

```
Query â†’ TRM Classifier (SARAi) â†’ Complexity Score (0.0-1.0)

< 0.5: Simple  â†’ SAUL direct response
â‰¥ 0.5: Complex â†’ RAG research + synthesis
```

### 2. Modality Detection

```
has_image OR has_audio â†’ Multimodal workflow
  â†’ Vision analysis / Audio transcription
  â†’ Research (if complex)
  â†’ Synthesis
```

### 3. Refinement Loop

```
While quality_score < threshold AND iterations < max:
  1. Evaluate quality (LLM-as-judge)
  2. Identify issues
  3. Refine response
  4. Re-evaluate
```

**Example flow**:
```
Query: "Explica agujeros negros"
  â†“
Complexity: 0.75 (complex)
  â†“
RAG Search â†’ 5 results
  â†“
LLM Synthesis â†’ Quality: 0.65 (below 0.7)
  â†“
Refinement Iteration 1 â†’ Quality: 0.78 âœ“
  â†“
Return result (2 iterations, 8.2s)
```

---

## ğŸ—ï¸ Project Structure

```
hlcs/
â”œâ”€â”€ proto/
â”‚   â”œâ”€â”€ hlcs.proto              # Main API (gRPC)
â”‚   â””â”€â”€ sarai_mcp.proto         # SARAi client protocol
â”‚
â”œâ”€â”€ src/hlcs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py         # Core logic (~250 LOC)
â”‚   â”œâ”€â”€ mcp_client.py           # SARAi MCP client (gRPC)
â”‚   â”‚
â”‚   â”œâ”€â”€ grpc_server/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py           # gRPC server
â”‚   â”‚   â”œâ”€â”€ hlcs_pb2.py         # Generated
â”‚   â”‚   â””â”€â”€ hlcs_pb2_grpc.py    # Generated
â”‚   â”‚
â”‚   â”œâ”€â”€ rest_gateway/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ server.py           # FastAPI gateway
â”‚   â”‚
â”‚   â”œâ”€â”€ reasoning/
â”‚   â”‚   â””â”€â”€ __init__.py         # Future: reasoning modules
â”‚   â”‚
â”‚   â”œâ”€â”€ planning/
â”‚   â”‚   â””â”€â”€ __init__.py         # Future: planning logic
â”‚   â”‚
â”‚   â””â”€â”€ metacognition/
â”‚       â””â”€â”€ __init__.py         # Future: self-reflection
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â”œâ”€â”€ test_grpc_api.py
â”‚   â”œâ”€â”€ test_mcp_client.py
â”‚   â””â”€â”€ test_e2e.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ hlcs.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_proto.sh       # Generate gRPC stubs
â”‚   â””â”€â”€ test_grpc.sh            # gRPC health check
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ³ Docker Deployment

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  # SARAi MCP Server (prerequisite)
  sarai-core:
    image: sarai:core
    ports:
      - "3000:3000"
    environment:
      - MCP_ENABLED=true
    networks:
      - sarai-network

  # HLCS (High-Level Consciousness)
  hlcs:
    build: .
    ports:
      - "4000:4000"  # gRPC
      - "4001:4001"  # REST
    environment:
      - SARAI_MCP_URL=http://sarai-core:3000
      - HLCS_GRPC_PORT=4000
      - HLCS_REST_PORT=4001
      - COMPLEXITY_THRESHOLD=0.5
      - QUALITY_THRESHOLD=0.7
      - MAX_ITERATIONS=3
    depends_on:
      - sarai-core
    networks:
      - sarai-network
    healthcheck:
      test: ["CMD", "grpcurl", "-plaintext", "localhost:4000", "hlcs.HLCS/HealthCheck"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  sarai-network:
    driver: bridge
```

---

## ğŸ“Š Performance Metrics

| Metric | Target | Actual (estimated) |
|--------|--------|-------------------|
| **gRPC Latency** | < 100ms | ~50ms (routing only) |
| **REST Latency** | < 150ms | ~80ms (+ transcoding) |
| **Simple Query E2E** | < 500ms | ~300ms (SAUL direct) |
| **Complex Query E2E** | < 10s | ~8s (RAG + synthesis) |
| **Multimodal E2E** | < 15s | ~12s (vision + research) |
| **Quality Score** | â‰¥ 0.7 | ~0.78 (avg) |
| **Throughput** | 100 req/s | ~80 req/s (single instance) |

---

## ğŸ”’ Security

- **gRPC TLS**: Production deployment uses TLS certificates
- **API Keys**: Optional authentication via metadata
- **Rate Limiting**: 100 req/min per client (configurable)
- **Input Validation**: Pydantic models for all inputs
- **Timeout Protection**: Default 30s per query

---

## ğŸ§ª Testing

```bash
## Testing

### Unit Tests
```bash
# Run all tests
pytest

# With coverage
pytest --cov=hlcs --cov-report=html

# Specific test file
pytest tests/test_orchestrator.py -v
```

### E2E Integration Tests

**Automated E2E Test** (recommended):
```bash
# Runs mock SARAi server + full integration tests
bash scripts/test_e2e.sh
```

This script:
1. Starts a mock SARAi MCP Server
2. Runs 10 comprehensive E2E tests
3. Validates HLCS â†” SARAi integration
4. Cleans up automatically

**Manual E2E Test**:
```bash
# Terminal 1: Start mock SARAi server
python tests/mock_sarai_server.py

# Terminal 2: Run E2E tests
export SARAI_MCP_URL="http://localhost:3100"
pytest tests/test_e2e_integration.py -v -s
```

**Test Coverage**:
- âœ… Connectivity HLCS â†” SARAi
- âœ… Direct tool calls (SAUL, TRM, RAG, Vision)
- âœ… Workflows (simple, complex, multimodal)
- âœ… Quality refinement loop
- âœ… Error handling and fallbacks
- âœ… Multi-turn conversations
- âœ… Performance benchmarks

**Results**: 10/10 tests passing âœ… (see `TESTING_REPORT.md` for details)

---


```

---

## ğŸ“ˆ Roadmap

### v1.0 (Current) âœ…
- [x] API-first gRPC design
- [x] Custom orchestrator
- [x] SARAi MCP integration
- [x] Dual gRPC/REST servers
- [x] Docker deployment

### v1.1 (Next)
- [ ] Reasoning modules (causal, analogical)
- [ ] Planning engine (goal decomposition)
- [ ] Metacognition (self-monitoring)
- [ ] LangGraph integration (optional, for complex workflows)
- [ ] CrewAI integration (optional, for multi-agent)

### v1.2 (Future)
- [ ] Autonomous learning loop
- [ ] Fine-tuning pipeline integration
- [ ] Multi-tenancy support
- [ ] Distributed tracing (OpenTelemetry)

---

## ğŸ”„ Migration Status

**sarai-agi Component Integration**: ğŸŸ¡ **AWAITING APPROVAL**

HLCS v3.0 is undergoing architectural analysis for integrating advanced components from the sarai-agi project. Critical collisions identified, HYBRID APPROACH strategy proposed.

**Key Documents**:
- ğŸ“‹ **[Migration Status](docs/SARAI_AGI_MIGRATION_STATUS.md)** - Quick overview
- ğŸš¨ **[Conflict Analysis](docs/MIGRATION_CONFLICT_ANALYSIS.md)** - Detailed collision analysis  
- ğŸ“œ **[ADR-001](docs/ADR-001-MIGRATION-STRATEGY.md)** - Architecture Decision Record

**Components Under Review**:
- âœ… Emotion System (safe to migrate)
- âœ… Monitoring & Observability (upgrade)
- âš ï¸ Meta-Reasoner (coexist with Planning)
- âš ï¸ Active Learning (coexist with RAG)
- ğŸ”´ LoRA Trainer (defer to v0.4)
- ğŸ”´ IntegratedConsciousness (defer merge to v0.4)

**Next Step**: ğŸ”´ Architecture Alignment Meeting (BLOCKER)

---

## ğŸ¤ Contributing

See `CONTRIBUTING.md` for development guidelines.

**Key principles**:
- **API-first**: Proto changes before implementation
- **Tests required**: >80% coverage
- **No heavy frameworks**: Keep orchestrator custom
- **gRPC primary**: REST is a gateway, not core

---

## ğŸ“„ License

MIT License - See `LICENSE`

---

## ğŸ™ Credits

- **SARAi Team**: Core AGI platform
- **gRPC**: High-performance RPC framework
- **FastAPI**: REST gateway

---

**Questions?** Open an issue or contact: team@iagenerativa.com
